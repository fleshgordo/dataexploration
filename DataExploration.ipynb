{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BpcKTMOGq7ow",
        "ZrPf3VlF8b2Q",
        "P04bL_TO_svJ",
        "u0DMWyoq_xVU",
        "G8oNR6NPDW7-",
        "_ry3EoZOEKb4",
        "sMD2RxGQWEY1",
        "XLYQfEmeWsyc",
        "9TjqGRiwW2cm",
        "7Kt2zZRsXgfw",
        "sc1eP4Z6dch9",
        "C18gcJ71dztp",
        "wtVceUTyewHA",
        "mu5oftNt7hW2",
        "RHqd_fd62M2J",
        "y2iplVGzrlsb",
        "vLr6qxP27PNL",
        "YSfEgpDeu_Bf",
        "DsbIxYwYvxvU",
        "ZyhYas8Oy7V3",
        "Ocz6G0fIwkEx",
        "VjrETHrPm3av",
        "uSgjLcklBXAo",
        "SZrNyr1d3509",
        "0MAoEN_n6tOL",
        "0dQ0mbH06N0M",
        "N_hAFvME8s89",
        "PSWJizzkc2GK"
      ],
      "mount_file_id": "1WrP57zsNaxt5sBG5Ox_cZx9MthCS3H-g",
      "authorship_tag": "ABX9TyMsiYS+dua+WEoohu/z9cFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fleshgordo/dataexploration/blob/main/DataExploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration with pandas"
      ],
      "metadata": {
        "id": "BpcKTMOGq7ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is a powerful and flexible Python library used for data manipulation and analysis. This handbook is designed to help you understand and master the fundamental concepts and operations of Pandas, making your data analysis tasks more efficient and insightful. And hopefully more fun.\n",
        "\n",
        "## What Will You Learn?\n",
        "\n",
        "- **Basics of Pandas**: Understand the core structures of Pandas.\n",
        "- **Data Manipulation**: Learn how to manipulate data in DataFrames including sorting, filtering, and aggregating data.\n",
        "- **Data Cleaning**: Techniques to handle missing data, remove duplicates, and fix data inconsistencies.\n",
        "- **Data visualisation** *italicised text*: Introduction to plotting with Pandas and its integration with Matplotlib for visual data analysis.\n",
        "\n",
        "I use pandas very often for quick and efficient analysis, not per se for visualisation since you can quickly reach its limits in terms of aesthetics. Nonetheless, it's great (plus really fast) for [data-crunching](https://www.netsuite.com/portal/resource/articles/erp/data-crunching.shtml). Once you did your analysis, you can export a clean CSV file which you can use later on."
      ],
      "metadata": {
        "id": "VKcy3qgg2f-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics\n",
        "\n",
        "Python is a versatile programming language that's great for handling data. While basic data structures like lists and dictionaries are useful, pandas provides a more powerful way to work with structured data."
      ],
      "metadata": {
        "id": "ZrPf3VlF8b2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple list in Python\n",
        "data = [1, 2, 3, 4, 5]\n",
        "print(data)\n",
        "print(f\"First entry is: {data[0]}\")"
      ],
      "metadata": {
        "id": "v3MBIvFb_jpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing pandas\n",
        "First, we need to import the pandas library to get started."
      ],
      "metadata": {
        "id": "P04bL_TO_svJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TlI1mQsT_uwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Sample Dataset\n",
        "\n",
        "We'll work with a simple dataset of six students, including their names, ages, and grades."
      ],
      "metadata": {
        "id": "u0DMWyoq_xVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'],\n",
        "    'Age': [20, 22, 19, 21, 22, 30],\n",
        "    'Grade': [88, 92, 85, 95, 92, 87]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "p0_mbjmf_1jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's view the DataFrame:"
      ],
      "metadata": {
        "id": "4BS-wkt9_4ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "dzotgRqd_402"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring the Data"
      ],
      "metadata": {
        "id": "WJOmq-W0BGom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first five rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nSMxbL_yBJQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the DataFrame Structure"
      ],
      "metadata": {
        "id": "XHUczjWoBK29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the DataFrame\n",
        "df.info()"
      ],
      "metadata": {
        "id": "EN9oyZOMBL4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descriptive Statistics"
      ],
      "metadata": {
        "id": "gpWPT4W1BRN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get statistical summary\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "XsjJUqTrBR6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the average values for the dataframe\n",
        "df.mean(numeric_only=True)"
      ],
      "metadata": {
        "id": "czz4PzyBCR0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show only one column of the data series"
      ],
      "metadata": {
        "id": "mk3A4qYOVx-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Age\"]"
      ],
      "metadata": {
        "id": "D5YWUvThV1om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data cleaning\n",
        "\n",
        "Checking for Missing Values"
      ],
      "metadata": {
        "id": "G8oNR6NPDW7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "u-6OD2q9DZYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our dataset is (still ;)) clean, there are no missing values. If there were, we could handle them using:"
      ],
      "metadata": {
        "id": "GaVUEekDDkfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values (if any)\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "H9KqcLSVDorU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for Duplicates"
      ],
      "metadata": {
        "id": "jHmiFNW1Dr7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate rows\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "YtBh32eXDtHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have duplicates you could again delete them via:"
      ],
      "metadata": {
        "id": "fp6WM4SgD8Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate rows (if any)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "iRGBcxDID_RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Type Conversion\n",
        "\n",
        "Sometimes you want to make sure that data types are appropriate. This can help to fix problems at later stage with data analysis. In many case, pandas will assign the correct data type while importing but sometimes you have to do it by hand. And in most cases, you don't really have to think about it. *italicised text*"
      ],
      "metadata": {
        "id": "_ry3EoZOEKb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "RSjzC02qE5JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the Name to a string type\n",
        "df[\"Age\"] = df['Age'].astype(float)\n",
        "df"
      ],
      "metadata": {
        "id": "-04PSGDzFS96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Filtering and Modification\n",
        "\n",
        "#### Filtering Data\n",
        "Select students who scored above 90."
      ],
      "metadata": {
        "id": "sMD2RxGQWEY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter students with grades above 90\n",
        "high_achievers = df[df['Grade'] > 90]\n",
        "high_achievers"
      ],
      "metadata": {
        "id": "Y0nQKUyJWGI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting is quite easy to achieve."
      ],
      "metadata": {
        "id": "5-5byqZhZOJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the DataFrame by Age\n",
        "df_sorted = df.sort_values('Age')\n",
        "#df_sorted = df.sort_values('Name')\n",
        "#df_sorted = df.sort_values('Grade',ascending=False)\n",
        "\n",
        "df_sorted"
      ],
      "metadata": {
        "id": "ymh8RnUUgqyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z2dX8-4dgu-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding a New Column\n",
        "Create a new column to categorize grades."
      ],
      "metadata": {
        "id": "XLYQfEmeWsyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to categorize grades\n",
        "def grade_category(grade):\n",
        "    if grade >= 90:\n",
        "        return 'A'\n",
        "    elif grade >= 80:\n",
        "        return 'B'\n",
        "    else:\n",
        "        return 'C'\n",
        "\n",
        "# Apply the function to create a new column\n",
        "df['Grade Category'] = df['Grade'].apply(grade_category)\n",
        "df"
      ],
      "metadata": {
        "id": "BRuHR91UWuZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updating Existing Data\n",
        "\n",
        "Students want better grades, right? Everyone's grade increases by 5 points. How can we achieve that?"
      ],
      "metadata": {
        "id": "9TjqGRiwW2cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase all grades by 5\n",
        "df['Grade'] = df['Grade'] + 5\n",
        "df"
      ],
      "metadata": {
        "id": "88g-73FuXAfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should avoid grades exceed the 100, right?"
      ],
      "metadata": {
        "id": "Ufih0oHNUWoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure grades do not exceed 100\n",
        "df['Grade'] = df['Grade'].apply(lambda x: 100 if x > 100 else x)\n",
        "df"
      ],
      "metadata": {
        "id": "LiEpURyDUbNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exporting Data\n",
        "\n",
        "Save the modified DataFrame to a new CSV file"
      ],
      "metadata": {
        "id": "mILmAN4ZXN9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export DataFrame to CSV (in colab have a look for newly created file csv)\n",
        "df.to_csv('students_modified.csv', index=False)\n",
        "\n",
        "# we use index=False to ignore the index that came along with pandas"
      ],
      "metadata": {
        "id": "AMQcP0kBXTgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Data\n",
        "\n",
        "CSV or JSON files can be imported quite easily"
      ],
      "metadata": {
        "id": "GSKJLMJ08ZM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('students_modified.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "u8kdnZzO8iyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisations\n",
        "\n",
        "Python has various plotting libraries. Most basic and famous one is matplotlib. First, as usual, let's import it:"
      ],
      "metadata": {
        "id": "7Kt2zZRsXgfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4bCUc-_oXrBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram of student ages\n",
        "df['Age'].hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a97PwzzWXvEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to give labels and a title, there are several plt functions available (more info [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel))"
      ],
      "metadata": {
        "id": "mVD99hpYX7Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram of student ages\n",
        "df['Age'].hist()\n",
        "plt.title('Age Distribution of Students')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of Students')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZR3k8J_hYCjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the plt Object\n",
        "The plt object acts as a convenient interface for creating and customising plots. Here's why we can use methods like hist, bar, etc.:\n",
        "\n",
        "* **plt.hist()**: Creates a histogram, which is useful for showing the distribution of a dataset.\n",
        "* **plt.bar()**: Generates a bar chart, ideal for comparing quantities across different categories.\n",
        "* **plt.plot()**: Plots data as lines and/or markers, commonly used for line graphs.\n",
        "* **plt.scatter()**: Creates a scatter plot, displaying values for typically two variables for a set of data.\n",
        "* **plt.pie()**: Generates a pie chart, representing data in terms of proportions.\n",
        "\n",
        "These functions internally manage the creation of figures, axes, and plots, allowing us to focus on the data visualisation rather than the underlying mechanics."
      ],
      "metadata": {
        "id": "oHoVdPqZY0Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar chart of student grades\n",
        "plt.bar(df['Name'], df['Grade'], color='skyblue')\n",
        "plt.title('Student Grades')\n",
        "plt.xlabel('Student Name')\n",
        "plt.ylabel('Grade')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(80, 100)  # Set y-axis limits for better visualisation\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lroer7pNYWX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scatter plot\n",
        "\n",
        "A scatter plot is useful for visualizing the relationship between two numerical variables. `plt.scatter()` plots individual data points."
      ],
      "metadata": {
        "id": "sc1eP4Z6dch9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a scatter plot of grades vs. age\n",
        "plt.scatter(df['Age'], df['Grade'], color='red', edgecolor='black')\n",
        "plt.title('Grades vs. Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Grade')\n",
        "plt.xticks(df['Age'].unique())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j_7RCJZJdfHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving plot\n",
        "\n",
        "You can save your plots to image files using `plt.savefig()`:"
      ],
      "metadata": {
        "id": "C18gcJ71dztp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the last plot as a PNG file\n",
        "plt.savefig('grades_vs_age.png',dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "2XWJP5uCd3nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case your png file is blank white,make sure you call savefig before the show() function:"
      ],
      "metadata": {
        "id": "bJvfnmpUeWlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a scatter plot of grades vs. age\n",
        "plt.scatter(df['Age'], df['Grade'], color='red', edgecolor='black')\n",
        "plt.title('Grades vs. Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Grade')\n",
        "plt.xticks(df['Age'].unique())\n",
        "plt.savefig('grades_vs_age.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z2r7fYNGecy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other librarires\n"
      ],
      "metadata": {
        "id": "wtVceUTyewHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotly\n",
        "\n",
        "Plotly is a graphing library that makes interactive, publication-quality graphs. It supports interactive plotting in Jupyter notebooks."
      ],
      "metadata": {
        "id": "Hr2upjOBfdsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Interactive scatter plot\n",
        "fig = px.scatter(df, x='Age', y='Grade', color='Grade Category',\n",
        "                 title='Grades vs. Age by Grade Category',\n",
        "                 labels={'Grade': 'Grade', 'Age': 'Age'},\n",
        "                 hover_data=['Name'])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5wqQYQ8wfiBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seaborn\n",
        "\n",
        "Seaborn is built on top of matplotlib and provides a high-level interface for creating attractive and informative statistical graphics."
      ],
      "metadata": {
        "id": "4QpeL554fpvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Scatter plot with regression line\n",
        "sns.lmplot(x='Age', y='Grade', data=df, hue='Grade Category', fit_reg=True)\n",
        "plt.title('Grades vs. Age with Regression Line')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nht4lOmYe2fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises"
      ],
      "metadata": {
        "id": "mu5oftNt7hW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Exercise 1\n",
        "Imagine what kind of analyis could be done with the dataset? Prepare first questions you want to \"ask\" to the dataset. Then try prompting to modify the `df` object by filtering, sorting, other analysis. Once you feel comfortable with the dataset, you can also extend your dataset by downloading a bigger student dataset (see section fake data)\n",
        "\n",
        "### Exercise 2 (individual)\n",
        "\n",
        "Try loading another CSV files from previous workshops. Can you load it into pandas? Can you batch modify values and visualise them?\n"
      ],
      "metadata": {
        "id": "XXHn4XN82K59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fake data\n"
      ],
      "metadata": {
        "id": "RHqd_fd62M2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can quickly generata a synthetic dataset for testing purposes. Make sure you imported the necessary libraries:"
      ],
      "metadata": {
        "id": "WEcgeVcF2O6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Optional: Install and import faker for realistic names\n",
        "!pip install faker\n",
        "from faker import Faker"
      ],
      "metadata": {
        "id": "gLxxGn1Dg9ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The faker library is helpful in creating \"fake\" real data. First, initialise it:"
      ],
      "metadata": {
        "id": "oUV1evmyhDzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker()"
      ],
      "metadata": {
        "id": "Beg0yn94hIW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's generate data in a loop"
      ],
      "metadata": {
        "id": "zQ56cyVChK8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store the data\n",
        "names = []\n",
        "ages = []\n",
        "grades = []\n",
        "\n",
        "# Generate data for 100 students\n",
        "for _ in range(100):\n",
        "    # Generate a fake name\n",
        "    name = fake.name()\n",
        "    names.append(name)\n",
        "\n",
        "    # Generate a random age between 18 and 30\n",
        "    age = random.randint(18, 30)\n",
        "    ages.append(age)\n",
        "\n",
        "    # Generate a random grade between 60 and 100\n",
        "    grade = random.randint(60, 100)\n",
        "    grades.append(grade)"
      ],
      "metadata": {
        "id": "Pg-OgPNGhNJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(names)\n",
        "print(grades)\n",
        "print(ages)"
      ],
      "metadata": {
        "id": "MPv17muyhOcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dataframe with pandas by passing the newly generated lists:"
      ],
      "metadata": {
        "id": "2aqV0S1whZkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with the data\n",
        "data = {\n",
        "    'Name': names,\n",
        "    'Age': ages,\n",
        "    'Grade': grades\n",
        "}\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NZ7Cg8uLhXsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "eNdc5lRFh2Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OECD data"
      ],
      "metadata": {
        "id": "fVrkngBG8Y8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the data"
      ],
      "metadata": {
        "id": "y2iplVGzrlsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Before we start we need to download the CSV files into our temporary drive. By executing following line you'll download all csv files"
      ],
      "metadata": {
        "id": "ykmABv1P16Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O example.zip \"https://drive.switch.ch/index.php/s/JeNWvdjnqn7BoHR/download\""
      ],
      "metadata": {
        "id": "Z-ctiEwlrk72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"example.zip\"\n",
        "#!head example.zip"
      ],
      "metadata": {
        "id": "JR2ehwfqm3GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "`!` allows you to run shell commands in Colab notebooks.\n",
        "\n",
        "`!wget` downloads the file at the provided path.\n",
        "\n",
        "`-O example.zip` specifies the output filename as example.zip.\n",
        "\n",
        "with `!unzip` we extract the zip file immediately after download."
      ],
      "metadata": {
        "id": "dIVa10ODtAhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/dimensions_scores_historic.csv')"
      ],
      "metadata": {
        "id": "SG8Q8nKdqiO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the core data structures in pandas is the DataFrame, which can be thought of as a table of data, with rows and columns.\n",
        "\n",
        "A **DataFrame** is a two-dimensional, size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). It is similar to a SQL table or an Excel spreadsheet. We store the dataframe in a variable called `df`\n"
      ],
      "metadata": {
        "id": "nHQH_-gUti5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "dcSpVa0wtikn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "8tHjgZqDr6ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Filtering"
      ],
      "metadata": {
        "id": "vLr6qxP27PNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before visualising we might want to filter the dataframe. It contains quite a lot of data. Let's focus on a specific year (2024) and a specific economy (choose one).\n",
        "\n",
        "Below we will output the dataframe and then click on the interactive chart icon (little pocket calculator on right side next to the table)"
      ],
      "metadata": {
        "id": "iwxk2-J51yUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_B3dgpNC7jJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a filter button which let's use apply various filter options and the possibility to immediately export the filtered dataset as CSV, JSON or Markdown file."
      ],
      "metadata": {
        "id": "rmoiUwu37584"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For applying a simple filter, you'll need to use the bracket syntax:"
      ],
      "metadata": {
        "id": "qOQ2icDm7pLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataframe for economy 'MNE' and year 2024\n",
        "df_filtered = df[(df['economy'] == 'MNE')]\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "dYyLB4RX8O4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's combine two filter options by using the `&` sign:"
      ],
      "metadata": {
        "id": "ru0OdvBJ8YDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataframe for economy 'MNE' and year 2024\n",
        "df_filtered = df[(df['economy'] == 'MNE') & (df['year'] == 2024)]\n",
        "\n",
        "# Be careful with data types 2024 != \"2024\"\n",
        "#df_filtered = df[(df['economy'] == 'MNE') & (df['year'] == \"2024\")]\n",
        "\n",
        "# Three filters all at once\n",
        "#df_filtered = df[(df['economy'] == 'MNE') & (df['year'] == 2024) & (df['key'] == \"TRADE\")]\n",
        "\n",
        "# Combine any ...\n",
        "#df_filtered = df[(df['key'] == \"TRADE\")]\n",
        "\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "k8o0ADeJ8eYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labels and scores"
      ],
      "metadata": {
        "id": "YSfEgpDeu_Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import labels and scores seperately"
      ],
      "metadata": {
        "id": "Vxl0cj7y1PuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labels\n",
        "dimensions_labels = pd.read_csv('dimensions_labels.csv')\n",
        "economies_labels = pd.read_csv('economies_labels.csv')\n",
        "indicators_labels = pd.read_csv('indicators_labels.csv')\n",
        "subdimensions_labels = pd.read_csv('subdimensions_labels.csv')\n",
        "\n",
        "# Load scores\n",
        "dimensions_scores = pd.read_csv('dimensions_scores.csv')\n",
        "indicators_scores = pd.read_csv('indicators_scores.csv')\n",
        "subdimensions_scores = pd.read_csv('subdimensions_scores.csv')\n"
      ],
      "metadata": {
        "id": "SPS_Vj36vEPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions_scores"
      ],
      "metadata": {
        "id": "6FGWZIPqvRN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can merge the two dataframes by using the same key as identifier:"
      ],
      "metadata": {
        "id": "iymk0lDpwDlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions_merged = pd.merge(dimensions_scores, dimensions_labels, on='key', how='left')\n",
        "dimensions_merged"
      ],
      "metadata": {
        "id": "mFGZKfHOvIMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QI3MHvq81MCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualising\n"
      ],
      "metadata": {
        "id": "DsbIxYwYvxvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Basics"
      ],
      "metadata": {
        "id": "ZyhYas8Oy7V3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's work with a small dataset to begin with. We use the filtered dataset which we've used before"
      ],
      "metadata": {
        "id": "9ZuAmBvW1G2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe df: filter for economy alb and year 2024\n",
        "\n",
        "# Filter the dataframe for economy 'ALB' and year 2024\n",
        "df_filtered = df[(df['economy'] == 'ALB') & (df['year'] == 2024)]\n",
        "\n",
        "# Display the filtered dataframe\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "gtuBAUm3wxDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a basic matplot function to create a bar-chart:"
      ],
      "metadata": {
        "id": "Q3jf5mJoyN1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(df_filtered['key'],df_filtered['score'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wEjKfuubyRua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quite messy, let's label the axis and use other colours:"
      ],
      "metadata": {
        "id": "bgU5XHLpz_a-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the bar chart\n",
        "plt.bar(df_filtered['key'], df_filtered['score'], color='skyblue', edgecolor='black')\n",
        "\n",
        "# Create the scatter plot\n",
        "#plt.scatter(df_filtered['key'], df_filtered['score'], color='green', s=100)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Scores by Key Industry', fontsize=16)\n",
        "plt.xlabel('Key Industry', fontsize=14)\n",
        "plt.ylabel('Score', fontsize=14)\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Add gridlines (optional)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.8)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "3oSY--YN0CkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Seaborn"
      ],
      "metadata": {
        "id": "Ocz6G0fIwkEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For plotting more advanced graphs we need to use an additional library called seaborn. [Matplot](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/) are popular python libraries to visualise data"
      ],
      "metadata": {
        "id": "U0XSDgJr1DfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Q2VaegHnvxbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "bar_plot = sns.barplot(x='economy', y='score', hue='year', data=df, errorbar=None)"
      ],
      "metadata": {
        "id": "nNypXfeSw75T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which key is the graph above actually using? It seems the values shown don't fit any key category. The barplot function aggregates automatically the values across all key entries (\"INDUSTRY\", \"ANTI_CORRUPTION\", etc...)\n",
        "\n",
        "If we want to visualise just one key aspect we'll filter first the df:"
      ],
      "metadata": {
        "id": "XQbEP8G_05vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume your original DataFrame is named df\n",
        "key_to_plot = 'INVESTMENT'\n",
        "\n",
        "# Filter the DataFrame for the specific key\n",
        "df_filtered = df[df['key'] == key_to_plot]\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "J5P2y_HW9XIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a selection\n",
        "bar_plot = sns.barplot(x='economy', y='score', hue='year', data=df_filtered, errorbar=None)"
      ],
      "metadata": {
        "id": "3p-upo1F_JpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting all keys into several plots\n",
        "\n",
        "For this we need to create a loop and iterate over the individual keys. Since each row has the key, we want to make sure first, that we only the unique entries (across the 15 keys)."
      ],
      "metadata": {
        "id": "3HmITWrj_klr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_keys = df['key'].unique()\n",
        "unique_keys"
      ],
      "metadata": {
        "id": "d-tELc5H1gS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over this array by using each key indiviually\n",
        "for key in unique_keys:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    subset = df[df['key'] == key]\n",
        "    sns.barplot(x='economy', y='score', hue='year', data=subset, palette='viridis')\n",
        "    plt.title(f'Scores by Country for {key} in 2024')\n",
        "    plt.xlabel('Country')\n",
        "    plt.ylabel('Score')\n",
        "    plt.legend(title='Year')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KUrNGxm-AASf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This becomes hard to read, since all the graphs are plotted one after the other. With catplot you can plot all keys into a multi-faceted plot. By passing `col='key'` it automatically produces a plot for each key:"
      ],
      "metadata": {
        "id": "RH6R5fxmAMuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.catplot(\n",
        "    x='economy',\n",
        "    y='score',\n",
        "    hue='year',\n",
        "    col='key',\n",
        "    data=df,\n",
        "    kind='bar',\n",
        "    col_wrap=3,  # Adjust based on how many plots you want per row\n",
        "    height=5,\n",
        "    aspect=1.5,\n",
        "    palette='viridis'\n",
        ")\n",
        "g.set_titles(\"{col_name}\")\n",
        "g.set_axis_labels(\"economy\", \"Score\")\n",
        "g.add_legend(title='Year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BMHb3Dwn1wbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plotly\n"
      ],
      "metadata": {
        "id": "VjrETHrPm3av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Plotly's Python graphing library makes interactive, publication-quality graphs. See [examples](https://plotly.com/python/) here.\n",
        "\n",
        "If not yet done, install plotly and import it:"
      ],
      "metadata": {
        "id": "zPIhx_bl0_b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "g_DxjeRUm4s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Create a bar chart\n",
        "fig = px.bar(df, x='economy', y='score', color='economy',facet_col='key',facet_row='year',title='test')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "MLBOuiWcm-ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a faceted line plot to visualise the trend of scores for each economy (country) over the years, separated by the 'key' column.\n",
        "fig = px.line(df,\n",
        "              x='year',\n",
        "              y='score',\n",
        "              color='economy',\n",
        "              facet_col='key',\n",
        "              markers=True,\n",
        "              facet_col_wrap=5,\n",
        "              title='Country Scores by Year, Separated by Key Category',\n",
        "              labels={'economy': 'Country', 'score': 'Score', 'year': 'Year'})\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "z5wk3dbssHgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sub-dimensions\n"
      ],
      "metadata": {
        "id": "uSgjLcklBXAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's look at the sub-dimension:"
      ],
      "metadata": {
        "id": "LhDVlQxU08Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's first load the subdimensions_labels.csv file to inspect its contents and see how we can merge it with the existing subdimensions_scores data.\n",
        "\n",
        "# Load the subdimensions labels CSV\n",
        "labels_df = pd.read_csv('/content/subdimensions_labels.csv')\n",
        "\n",
        "# Display the first few rows of the labels DataFrame to inspect\n",
        "labels_df.head()\n",
        "\n",
        "subdimensions_df = pd.read_csv('/content/subdimensions_scores.csv')\n",
        "subdimensions_df"
      ],
      "metadata": {
        "id": "kDvbXPwY9Ufi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subdimensions_df.info()"
      ],
      "metadata": {
        "id": "fwvYi2MKBr2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df"
      ],
      "metadata": {
        "id": "VMNKQjdC9-Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For better readability let's merge them. The `merge()` function can merge two dataframes. You need to specify which column is the combined one (existing in both dataframes). The new dataframe is saved in a variable `merged_df`"
      ],
      "metadata": {
        "id": "G19xFf_XJZ7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Merge the subdimensions_scores and labels dataframes based on the 'key' column\n",
        "merged_df = pd.merge(subdimensions_df, labels_df, on='key', how='left')\n",
        "\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "_YP7C91ECFCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a heatmap with plotly"
      ],
      "metadata": {
        "id": "Mk_ROHoACMQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "slRcFll1LbcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pivot table for the heatmap using the 'label' column for the labels\n",
        "heatmap_data_with_labels = merged_df.pivot_table(index='economy', columns='label', values='score', aggfunc='mean')\n",
        "\n",
        "# Plot the updated heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(heatmap_data_with_labels, annot=False, cmap='viridis', linewidths=.5)\n",
        "plt.title('Scores Heatmap by Economy and Sub-dimension')\n",
        "plt.xlabel('Sub-dimension')\n",
        "plt.ylabel('Country')\n",
        "plt.xticks(rotation=90,fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xl9hfxN79obJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "cRVcL4m5-Kgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for keys containing \"DIGITAL\"\n",
        "keyword = \"DIGITAL\"\n",
        "filtered_df = merged_df[merged_df['key'].str.contains(keyword)]\n",
        "\n",
        "# Filter for the year 2024\n",
        "filtered_df = filtered_df[filtered_df['year'] == 2024]\n",
        "\n",
        "# Create a pivot table for the heatmap using the 'label' column for the labels\n",
        "heatmap_data_with_labels = filtered_df.pivot_table(index='economy', columns='label', values='score', aggfunc='mean')\n",
        "\n",
        "# Plot the updated heatmap\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.heatmap(heatmap_data_with_labels, annot=False, vmin=0, vmax=5, cmap='YlGnBu', linewidths=.5)\n",
        "plt.title(f'Scores Heatmap by Economy and Sub-dimension {keyword}')\n",
        "plt.xlabel('Sub-dimension')\n",
        "plt.ylabel('Country')\n",
        "plt.xticks(rotation=90,fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-DylwRbDIu8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any missing scores in the merged DataFrame\n",
        "missing_scores = merged_df.isnull().sum()\n",
        "print(missing_scores)"
      ],
      "metadata": {
        "id": "6EF6_vmL_vGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An interactive heatmap"
      ],
      "metadata": {
        "id": "SZrNyr1d3509"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating an interactive heatmap using Plotly enables a detailed examination of multidimensional data by visually representing the relationships between variables. The provided code creates a pivot table from merged_df to restructure the data with economies on the y-axis and labels (sub-dimensions) on the x-axis, displaying their corresponding scores as color intensities. This visualization facilitates the detection of patterns, trends, and outliers in country scores across various sub-dimensions."
      ],
      "metadata": {
        "id": "HHDvqeul5d3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create the pivot table for the heatmap using the 'label' column for the labels\n",
        "heatmap_data_with_labels = merged_df.pivot_table(index='economy', columns='label', values='score', aggfunc='mean')\n",
        "\n",
        "# Create the heatmap\n",
        "fig = go.Figure(data=go.Heatmap(\n",
        "                   z=heatmap_data_with_labels.values,\n",
        "                   x=heatmap_data_with_labels.columns,\n",
        "                   y=heatmap_data_with_labels.index,\n",
        "                   #colorscale='Viridis',\n",
        "                   hoverongaps=False,  # Show hover info even on gaps\n",
        "                   showscale=True))  # Show color scale bar\n",
        "\n",
        "# Set title and axis labels\n",
        "fig.update_layout(\n",
        "    title='Interactive Heatmap: Country Scores by Sub-dimension',\n",
        "    xaxis_nticks=50,\n",
        "    xaxis_title='Sub-dimension',\n",
        "    yaxis_title='Country',\n",
        "    height=600  # Increase the figure height (adjust as needed)\n",
        ")\n",
        "\n",
        "# Show the interactive plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "z03-9C6uDWMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pivoting"
      ],
      "metadata": {
        "id": "0MAoEN_n6tOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pivoting is used in the example to transform the filtered DataFrame into a format where each economy is a row and each sub-dimension category related to 'DIGITAL' is a column, with the corresponding scores as cell values. This restructuring allows for easier comparison of economies across different digital sub-dimensions"
      ],
      "metadata": {
        "id": "-6rZ7L_Q7HQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter the data for a specific sub-dimension (e.g., DIGITAL)\n",
        "subdimension_key = 'DIGITAL'\n",
        "filtered_df = merged_df[merged_df['key'].str.startswith(subdimension_key)]\n",
        "\n",
        "# Example: We'll aggregate the scores for one year (you can change this as needed)\n",
        "year_of_interest = 2024\n",
        "filtered_year_df = filtered_df[filtered_df['year'] == year_of_interest]\n",
        "\n",
        "# Pivot the data to have economies as rows and subdimension categories as columns\n",
        "pivot_data = filtered_year_df.pivot_table(index='economy', columns='key', values='score', aggfunc='mean')\n",
        "pivot_data"
      ],
      "metadata": {
        "id": "CtfjDustI5N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Radarchart"
      ],
      "metadata": {
        "id": "0dQ0mbH06N0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lots of code for creating a 180degrees radarchart but most of it is setup and adjusting the angles"
      ],
      "metadata": {
        "id": "2-V1EgWq6QUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter the data for a specific sub-dimension (e.g., DIGITAL)\n",
        "subdimension_key = 'DIGITAL'\n",
        "filtered_df = merged_df[merged_df['key'].str.startswith(subdimension_key)]\n",
        "\n",
        "# Example: We'll aggregate the scores for one year (you can change this as needed)\n",
        "year_of_interest = 2024\n",
        "filtered_year_df = filtered_df[filtered_df['year'] == year_of_interest]\n",
        "\n",
        "# Pivot the data to have economies as rows and subdimension categories as columns\n",
        "pivot_data = filtered_year_df.pivot_table(index='economy', columns='label', values='score', aggfunc='mean')\n",
        "\n",
        "# Prepare the radar chart\n",
        "categories = pivot_data.columns\n",
        "N = len(categories)\n",
        "\n",
        "# Compute the angle for each category\n",
        "angles = np.linspace(0, np.pi, N, endpoint=True).tolist()\n",
        "# Complete the loop for radar by repeating the first category\n",
        "angles += angles[:1]\n",
        "\n",
        "#print(filtered_year_df)\n",
        "#print(pivot_data)\n",
        "# Set up the radar chart in polar coordinates\n",
        "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "\n",
        "# Plot data for each country\n",
        "for i, country in enumerate(pivot_data.index):\n",
        "    scores = pivot_data.loc[country].values\n",
        "    scores = np.concatenate((scores, [scores[0]]))  # Close the loop for the radar chart\n",
        "\n",
        "    ax.fill(angles, scores, alpha=0.1)  # Fill the area\n",
        "    ax.plot(angles, scores, linewidth=2, label=country)  # Plot the outline for each country\n",
        "\n",
        "# Set the category labels\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories, size=10)\n",
        "\n",
        "# Set the title\n",
        "ax.set_title(f'Radar Chart for {subdimension_key} Sub-dimensions ({year_of_interest})')\n",
        "\n",
        "# Add legend\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "ax.set_thetamax(180)\n",
        "# Show the chart\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UJ4DjW7-JNY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "fELEGDt5UUgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Troubleshooting\n"
      ],
      "metadata": {
        "id": "N_hAFvME8s89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Do you see this error? `NameError: name 'pd' is not defined` - Make sure you imported pandas"
      ],
      "metadata": {
        "id": "ifMXOgGT2j3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bgjSDu548xBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Resources\n"
      ],
      "metadata": {
        "id": "PSWJizzkc2GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   [Matplotlib Gallery](https://matplotlib.org/stable/gallery/index.html): Explore a wide range of plots and their code examples.\n",
        "*   [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html): Step-by-step tutorials on various aspects of matplotlib.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H8nzddL12ml5"
      }
    }
  ]
}